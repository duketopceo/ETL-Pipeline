{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust ETL Pipeline for Job Data Consolidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements a robust, interactive ETL pipeline. It is designed with defensive programming principles to provide clear feedback and avoid crashing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Package Validation\n",
    "\n",
    "This cell checks if all required packages are installed in your environment. Run this first to ensure the notebook will work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib.util\n",
    "import importlib.metadata\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "print(\"Performing package validation...\")\n",
    "\n",
    "required_packages = {\n",
    "    'pandas': '1.3.5',\n",
    "    'numpy': '1.21.5',\n",
    "    'ipywidgets': '7.6.5'\n",
    "}\n",
    "\n",
    "built_in_modules = ['re', 'io', 'functools', 'sys']\n",
    "all_ok = True\n",
    "\n",
    "display(HTML(\"<b>Checking built-in modules:</b>\"))\n",
    "for module in built_in_modules:\n",
    "    display(HTML(f\"&nbsp;&nbsp;✅ <b>{module}</b>: Available (built-in)\"))\n",
    "\n",
    "display(HTML(\"<b>Checking installed packages:</b>\"))\n",
    "for package, min_version in required_packages.items():\n",
    "    spec = importlib.util.find_spec(package)\n",
    "    if spec is not None:\n",
    "        version = importlib.metadata.version(package)\n",
    "        display(HTML(f'&nbsp;&nbsp;✅ <b>{package}</b>: Installed (Version: {version})'))\n",
    "    else:\n",
    "        all_ok = False\n",
    "        display(HTML(f' &nbsp;&nbsp;❌ <b>{package}</b>: Not found. Please install it by running: <code>pip install \"{package}>={min_version}\"</code>'))\n",
    "\n",
    "if all_ok:\n",
    "    display(HTML('<b style=\"color:green;\">✅ All required packages are installed.</b>'))\n",
    "else:\n",
    "    display(HTML('<b style=\"color:red;\">❌ Some required packages are missing. Please install them before proceeding.</b>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup Pipeline\n",
    "\n",
    "This cell initializes the pipeline's status tracking object and helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import re\n",
    "from functools import reduce\n",
    "import subprocess\n",
    "\n",
    "pipeline_status = {\n",
    "    'setup':        {'status': 'pending'},\n",
    "    'upload':       {'status': 'pending'},\n",
    "    'load':         {'status': 'pending', 'data': []},\n",
    "    'extract':      {'status': 'pending', 'data': []},\n",
    "    'merge':        {'status': 'pending', 'data': None},\n",
    "    'completeness': {'status': 'pending', 'data': None},\n",
    "    'export':       {'status': 'pending'}\n",
    "}\n",
    "\n",
    "def print_status(stage, status, message):\n",
    "    icons = {'success': '✅', 'error': '❌', 'warning': '⚠️', 'info': 'ℹ️'}\n",
    "    pipeline_status[stage]['status'] = status\n",
    "    pipeline_status[stage]['message'] = message\n",
    "    display(HTML(f\"<b>{icons.get(status, 'ℹ️')} {stage.capitalize()}:</b> {message}\"))\n",
    "\n",
    "print_status('setup', 'success', 'Pipeline initialized successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Upload CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    print(f\"Attempting to install {package}...\")\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "        print(f\"✅ {package} installed successfully.\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ Failed to install {package}. Error: {e}\")\n",
    "        return False\n",
    "\n",
    "ipywidgets_available = False\n",
    "uploader = None\n",
    "\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "    ipywidgets_available = True\n",
    "except ImportError:\n",
    "    print(\"⚠️ ipywidgets not found.\")\n",
    "    if install_package(\"ipywidgets\"):\n",
    "        import importlib\n",
    "        import ipywidgets as widgets\n",
    "        importlib.reload(widgets)\n",
    "        from IPython.display import display\n",
    "        ipywidgets_available = True\n",
    "\n",
    "if 'pipeline_status' not in locals():\n",
    "    display(HTML('<b style=\\\"color:red;\\\">❌ Pipeline status not initialized. Please run the Setup cell first.</b>'))\n",
    "else:\n",
    "    if ipywidgets_available:\n",
    "        try:\n",
    "            uploader = widgets.FileUpload(\n",
    "                accept='.csv',\n",
    "                multiple=True,\n",
    "                description='Upload CSVs',\n",
    "                button_style='primary'\n",
    "            )\n",
    "            display(uploader)\n",
    "            print_status('upload', 'info', 'Widget ready. Please upload your CSV files.')\n",
    "        except Exception as e:\n",
    "            error_message = f\"Could not display file upload widget. Error: {e}.\"\n",
    "            print_status('upload', 'error', error_message)\n",
    "    else:\n",
    "        error_message = \"ipywidgets could not be installed or imported. This notebook requires an environment that supports ipywidgets.\"\n",
    "        print_status('upload', 'error', error_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load & Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "loaded_files = []\n",
    "failed_files = {}\n",
    "\n",
    "if 'uploader' not in locals() or uploader is None:\n",
    "    print_status('load', 'error', 'File uploader widget not found. Please run the preceding cells.')\n",
    "elif not uploader.value:\n",
    "    print_status('load', 'warning', 'No files uploaded. Please upload at least one CSV file.')\n",
    "elif 'pipeline_status' not in locals():\n",
    "    display(HTML('<b style=\"color:red;\">❌ Pipeline status not initialized. Please run the Setup cell first.</b>'))\n",
    "else:\n",
    "    for file_info in uploader.value:\n",
    "        file_name = file_info['name']\n",
    "        try:\n",
    "            content = file_info['content']\n",
    "            df = pd.read_csv(io.BytesIO(content))\n",
    "\n",
    "            if df.empty:\n",
    "                raise ValueError(\"The CSV file is empty or could not be parsed correctly.\")\n",
    "\n",
    "            dfs.append(df)\n",
    "            loaded_files.append(file_name)\n",
    "            print(f\"✅ Successfully loaded and validated '{file_name}'.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            failed_files[file_name] = str(e)\n",
    "            print(f\"❌ Failed to load '{file_name}'. Error: {e}\")\n",
    "\n",
    "    success_count = len(loaded_files)\n",
    "    failure_count = len(failed_files)\n",
    "    total_count = success_count + failure_count\n",
    "\n",
    "    summary_message = f\"Processed {total_count} file(s): {success_count} succeeded, {failure_count} failed.\"\n",
    "    if failure_count > 0:\n",
    "        print_status('load', 'warning', summary_message + \" See details above.\")\n",
    "    elif success_count == 0:\n",
    "        print_status('load', 'error', \"No data was loaded. Please check your uploaded files.\")\n",
    "    else:\n",
    "        print_status('load', 'success', summary_message)\n",
    "\n",
    "    pipeline_status['load']['data'] = dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract Job ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dfs = []\n",
    "\n",
    "if 'dfs' not in locals() or not dfs:\n",
    "    print_status('extract', 'warning', 'No dataframes to process. Please run the data loading cell first.')\n",
    "elif 'pipeline_status' not in locals():\n",
    "    display(HTML('<b style=\"color:red;\">❌ Pipeline status not initialized. Please run the Setup cell first.</b>'))\n",
    "else:\n",
    "    def find_url_column(df):\n",
    "        url_patterns = ['url', 'link', 'href', 'reference']\n",
    "        for col in df.columns:\n",
    "            col_lower = col.lower()\n",
    "            if any(pattern in col_lower for pattern in url_patterns):\n",
    "                return col\n",
    "        return None\n",
    "\n",
    "    def extract_job_id(df, url_column):\n",
    "        if url_column is None:\n",
    "            df['job_id'] = None\n",
    "            return df, 0\n",
    "        \n",
    "        df['job_id'] = df[url_column].str.extract(r'(\\d+)', expand=False)\n",
    "        successful_extractions = df['job_id'].notna().sum()\n",
    "        df['job_id'] = pd.to_numeric(df['job_id'], errors='coerce')\n",
    "        return df, successful_extractions\n",
    "\n",
    "    print(\"Starting Job ID extraction...\")\n",
    "    total_extractions = 0\n",
    "    total_rows = 0\n",
    "\n",
    "    for i, df in enumerate(dfs):\n",
    "        df_copy = df.copy()\n",
    "        total_rows += len(df_copy)\n",
    "        try:\n",
    "            print(f\"Processing DataFrame #{i+1}...\")\n",
    "            url_col = find_url_column(df_copy)\n",
    "            \n",
    "            if url_col is None:\n",
    "                print(f\"⚠️ Warning: No URL column found in DataFrame #{i+1}. Cannot extract job IDs.\")\n",
    "            else:\n",
    "                print(f\"Found URL column: '{url_col}' in DataFrame #{i+1}.\")\n",
    "            \n",
    "            df_processed, extracted_count = extract_job_id(df_copy, url_col)\n",
    "            total_extractions += extracted_count\n",
    "            \n",
    "            if url_col:\n",
    "                df_processed = df_processed.drop(columns=[url_col])\n",
    "            \n",
    "            processed_dfs.append(df_processed)\n",
    "            print(f\"✅ Finished processing DataFrame #{i+1}. Extracted {extracted_count} job IDs.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing DataFrame #{i+1}: {e}\")\n",
    "            df_copy['job_id'] = None\n",
    "            processed_dfs.append(df_copy)\n",
    "\n",
    "    if not processed_dfs:\n",
    "        print_status('extract', 'error', 'Job ID extraction failed for all dataframes.')\n",
    "    else:\n",
    "        summary_message = f\"Extracted {total_extractions} job IDs from {total_rows} total rows across {len(dfs)} dataframe(s).\"\n",
    "        print_status('extract', 'success', summary_message)\n",
    "\n",
    "    pipeline_status['extract']['data'] = processed_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = None\n",
    "\n",
    "if 'processed_dfs' not in locals() or not processed_dfs:\n",
    "    print_status('merge', 'warning', 'No dataframes to merge. Please run the extraction cell first.')\n",
    "elif 'pipeline_status' not in locals():\n",
    "    display(HTML('<b style=\"color:red;\">❌ Pipeline status not initialized. Please run the Setup cell first.</b>'))\n",
    "else:\n",
    "    valid_dfs_to_merge = []\n",
    "    for i, df in enumerate(processed_dfs):\n",
    "        if 'job_id' not in df.columns:\n",
    "            print(f\"⚠️ Warning: DataFrame #{i+1} is missing the 'job_id' column and will be skipped.\")\n",
    "            continue\n",
    "        if df['job_id'].isnull().all():\n",
    "            print(f\"⚠️ Warning: DataFrame #{i+1} has no valid 'job_id' values and will be skipped.\")\n",
    "            continue\n",
    "        valid_dfs_to_merge.append(df)\n",
    "\n",
    "    if len(valid_dfs_to_merge) == 0:\n",
    "        print_status('merge', 'error', 'No valid dataframes available to merge.')\n",
    "    elif len(valid_dfs_to_merge) == 1:\n",
    "        merged_df = valid_dfs_to_merge[0]\n",
    "        print_status('merge', 'success', 'Only one valid dataframe found. No merge needed.')\n",
    "        display(merged_df.head())\n",
    "    else:\n",
    "        try:\n",
    "            print(f\"Merging {len(valid_dfs_to_merge)} dataframes on 'job_id'...\")\n",
    "            merged_df = reduce(lambda left, right: pd.merge(left, right, on='job_id', how='outer'), valid_dfs_to_merge)\n",
    "            \n",
    "            message = f\"Successfully merged {len(valid_dfs_to_merge)} dataframes. Resulting dataset has {merged_df.shape[0]} rows and {merged_df.shape[1]} columns.\"\n",
    "            print_status('merge', 'success', message)\n",
    "            print(\"Sample of merged data:\")\n",
    "            display(merged_df.head())\n",
    "\n",
    "        except Exception as e:\n",
    "            merged_df = None\n",
    "            error_message = f\"An unexpected error occurred during merging: {e}\"\n",
    "            print_status('merge', 'error', error_message)\n",
    "\n",
    "pipeline_status['merge']['data'] = merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Completeness Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completeness_report = None\n",
    "\n",
    "if 'merged_df' not in locals() or merged_df is None:\n",
    "    print_status('completeness', 'warning', 'No merged dataframe to analyze. Please run the merge cell first.')\n",
    "elif not isinstance(merged_df, pd.DataFrame) or merged_df.empty:\n",
    "    print_status('completeness', 'warning', 'The merged dataframe is empty. Nothing to analyze.')\n",
    "elif 'pipeline_status' not in locals():\n",
    "    display(HTML('<b style=\"color:red;\">❌ Pipeline status not initialized. Please run the Setup cell first.</b>'))\n",
    "else:\n",
    "    try:\n",
    "        print(\"Running data completeness analysis...\")\n",
    "        \n",
    "        df_to_check = merged_df.copy()\n",
    "\n",
    "        df_to_check.replace(r'^\\s*$', np.nan, regex=True, inplace=True)\n",
    "        \n",
    "        missing_values = df_to_check.isnull().sum()\n",
    "        total_rows = len(df_to_check)\n",
    "        completeness_percentage = ((total_rows - missing_values) / total_rows) * 100\n",
    "        \n",
    "        completeness_report = pd.DataFrame({\n",
    "            'Missing Values': missing_values,\n",
    "            'Completeness (%)': completeness_percentage\n",
    "        })\n",
    "        \n",
    "        completeness_report.sort_values(by='Completeness (%)', ascending=True, inplace=True)\n",
    "        \n",
    "        print(\"Completeness Report (Problematic columns first):\")\n",
    "        display(completeness_report)\n",
    "        \n",
    "        avg_completeness = completeness_report['Completeness (%)'].mean()\n",
    "        min_completeness = completeness_report['Completeness (%)'].min()\n",
    "        print(f\"\\nSummary Statistics:\\n- Average Column Completeness: {avg_completeness:.2f}%\\n- Minimum Column Completeness: {min_completeness:.2f}%\")\n",
    "\n",
    "        try:\n",
    "            print(\"\\n--- Markdown Summary ---\")\n",
    "            print(completeness_report.to_markdown())\n",
    "        except Exception as md_e:\n",
    "            print(f\"⚠️ Could not generate Markdown report: {md_e}\")\n",
    "\n",
    "        print_status('completeness', 'success', f\"Analysis complete. Average column completeness is {avg_completeness:.2f}%.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        error_message = f\"An unexpected error occurred during completeness analysis: {e}\"\n",
    "        print_status('completeness', 'error', error_message)\n",
    "\n",
    "pipeline_status['completeness']['data'] = completeness_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'merged_df' not in locals() or not isinstance(merged_df, pd.DataFrame) or merged_df.empty:\n",
    "    print_status('export', 'warning', 'No valid data to export. Skipping export.')\n",
    "elif 'pipeline_status' not in locals():\n",
    "    display(HTML('<b style=\"color:red;\">❌ Pipeline status not initialized. Please run the Setup cell first.</b>'))\n",
    "else:\n",
    "    try:\n",
    "        export_filename = 'consolidated_jobs.csv'\n",
    "        merged_df.to_csv(export_filename, index=False)\n",
    "        print_status('export', 'success', f'Successfully exported the consolidated dataset to <code>{export_filename}</code>.')\n",
    "    except Exception as e:\n",
    "        error_message = f\"An unexpected error occurred during file export: {e}\"\n",
    "        print_status('export', 'error', error_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Pipeline Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(\"<h2>Pipeline Execution Summary</h2>\"))\n",
    "\n",
    "if 'pipeline_status' not in locals():\n",
    "    display(HTML('<b style=\"color:red;\">❌ Pipeline status not initialized. Please run the Setup cell first.</b>'))\n",
    "else:\n",
    "    for stage, info in pipeline_status.items():\n",
    "        status = info.get('status', 'pending')\n",
    "        message = info.get('message', 'No message recorded.')\n",
    "        icons = {'success': '✅', 'error': '❌', 'warning': '⚠️', 'info': 'ℹ️', 'pending': '⚪'}\n",
    "        icon = icons.get(status, 'ℹ️')\n",
    "        \n",
    "        troubleshooting_tips = {\n",
    "            'upload': 'If this failed, your browser environment might not support ipywidgets, or the installation failed.',\n",
    "            'load': 'If this failed, check that you uploaded valid, non-empty CSV files.',\n",
    "            'extract': 'If this failed, ensure your files contain a column with \\\"url\\\" or \\\"link\\\" in the name, and that they contain numeric job IDs.',\n",
    "            'merge': 'If this failed, it might be because no dataframes had a valid \\\"job_id\\\" column to join on.',\n",
    "            'completeness': 'A failure here is likely due to an issue with the merged dataframe.',\n",
    "            'export': 'A failure here could be due to file system permission issues.'\n",
    "        }\n",
    "        \n",
    "        status_html = f\"<b>{icon} {stage.capitalize()}:</b> [{status.upper()}] {message}\"\n",
    "        if status in ['error', 'warning']:\n",
    "            status_html += f\"<br>&nbsp;&nbsp;<i><b>Tip:</b> {troubleshooting_tips.get(stage, 'Check previous cells for errors.')}</i>\"\n",
    "        \n",
    "        display(HTML(status_html))\n",
    "\n",
    "    display(HTML(\"<h3>Variable Availability for Debugging</h3>\"))\n",
    "    variables_to_check = ['uploader', 'dfs', 'processed_dfs', 'merged_df', 'completeness_report']\n",
    "    for var in variables_to_check:\n",
    "        if var in locals() and locals()[var] is not None:\n",
    "            if isinstance(locals()[var], (list, pd.DataFrame)) and not len(locals()[var]) == 0:\n",
    "                 display(HTML(f\"✅ <code>{var}</code> is available.\"))\n",
    "            elif not isinstance(locals()[var], (list, pd.DataFrame)):\n",
    "                 display(HTML(f\"✅ <code>{var}</code> is available.\"))\n",
    "            else:\n",
    "                 display(HTML(f\"⚠️ <code>{var}</code> is available but it is empty.\"))\n",
    "        else:\n",
    "            display(HTML(f\"❌ <code>{var}</code> is not available or is None.\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
